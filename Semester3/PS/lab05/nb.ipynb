{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean is the average value of a dataset and is computed as:**\n",
    "$$\n",
    "\\bar{X} = \\frac{\\sum (X_i \\cdot f_X)}{\\sum f_X}\n",
    "$$\n",
    "\n",
    "**Variance**\n",
    "\n",
    "Variance measures the spread of data. For a weighted dataset:\n",
    "\n",
    "$$\n",
    "\\sigma^2_X = \\frac{\\sum f_X \\cdot (X_i - \\bar{X})^2}{\\sum f_X}\n",
    "$$\n",
    "\n",
    "\n",
    "**Covariance**\n",
    "\n",
    "Covariance shows the relationship between two variables:\n",
    "\n",
    "$$\n",
    "\\text{cov}(X, Y) = \\frac{\\sum f_X f_Y \\cdot (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum f_X \\cdot f_Y}\n",
    "$$\n",
    "\n",
    "\n",
    "**Correlation Coefficient**\n",
    "\n",
    "The correlation coefficient quantifies the strength of the relationship:\n",
    "\n",
    "$$\n",
    "\\rho_{XY} = \\frac{\\text{cov}(X, Y)}{\\sqrt{\\sigma^2_X \\cdot \\sigma^2_Y}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of X: 23.866666666666667\n",
      "Mean of Y: 78.53333333333333\n",
      "Variance of X: 3.115555555555555\n",
      "Variance of Y: 3.1155555555555554\n",
      "Covariance of X and Y: 0.313283950617284\n",
      "Correlation Coefficient: 0.1005547630369314\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# X and Y data with frequencies\n",
    "X = np.array([20, 21, 22, 23, 24, 25, 26, 27])\n",
    "f_X = np.array([2, 1, 3, 6, 5, 9, 2, 2])\n",
    "\n",
    "Y = np.array([75, 76, 77, 78, 79, 80, 81, 82])\n",
    "f_Y = np.array([3, 2, 2, 5, 8, 8, 1, 1])\n",
    "\n",
    "# Mean\n",
    "mean_X = np.sum(X * f_X) / np.sum(f_X)\n",
    "mean_Y = np.sum(Y * f_Y) / np.sum(f_Y)\n",
    "\n",
    "# Variance\n",
    "var_X = np.sum(f_X * (X - mean_X)**2) / np.sum(f_X)\n",
    "var_Y = np.sum(f_Y * (Y - mean_Y)**2) / np.sum(f_Y)\n",
    "\n",
    "# Covariance\n",
    "cov_XY = np.sum(f_X * f_Y * (X - mean_X) * (Y - mean_Y)) / (np.sum(f_X) * np.sum(f_Y))\n",
    "\n",
    "# Correlation coefficient\n",
    "corr_coef = cov_XY / np.sqrt(var_X * var_Y)\n",
    "\n",
    "# Results\n",
    "print(\"Mean of X:\", mean_X)\n",
    "print(\"Mean of Y:\", mean_Y)\n",
    "print(\"Variance of X:\", var_X)\n",
    "print(\"Variance of Y:\", var_Y)\n",
    "print(\"Covariance of X and Y:\", cov_XY)\n",
    "print(\"Correlation Coefficient:\", corr_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theory**\n",
    "\n",
    "1. **Confidence Interval for the Mean**\n",
    "\n",
    "The confidence interval (CI) for the mean of a normal distribution with unknown variance is given by:\n",
    "\n",
    "$$\n",
    "\\text{CI for } \\mu = \\left[ \\bar{X} - t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}}, \\, \\bar{X} + t_{\\alpha/2, n-1} \\cdot \\frac{s}{\\sqrt{n}} \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{X}$  = sample mean.\n",
    "- $s$  = sample standard deviation.\n",
    "- $n$  = sample size.\n",
    "- $t_{\\alpha/2, n-1}$  = critical value from the  $t$ -distribution for  $n-1$  degrees of freedom and confidence level  $1 - \\alpha$.\n",
    "\n",
    "<br>\n",
    "\n",
    "2. **Confidence Interval for the Variance**\n",
    "\n",
    "The confidence interval for the variance is based on the chi-square distribution:\n",
    "\n",
    "$$\n",
    "\\text{CI for } \\sigma^2 = \\left[ \\frac{(n-1) \\cdot s^2}{\\chi^2_{1-\\alpha/2, n-1}}, \\, \\frac{(n-1) \\cdot s^2}{\\chi^2_{\\alpha/2, n-1}} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- $s^2$  = sample variance.\n",
    "- $ \\chi^2_{1-\\alpha/2, n-1}$  and  $\\chi^2_{\\alpha/2, n-1}$  are critical values from the chi-square distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 23.866666666666667\n",
      "Sample Variance: 3.115555555555555\n",
      "95% CI for the Mean: (23.2075698697932, 24.525763463540134)\n",
      "95% CI for the Variance: (1.9760847368409975, 5.630379973762348)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t, chi2\n",
    "\n",
    "# Data\n",
    "X = np.array([20, 21, 22, 23, 24, 25, 26, 27])  # Values\n",
    "f_X = np.array([2, 1, 3, 6, 5, 9, 2, 2])       # Frequencies\n",
    "\n",
    "# Confidence level\n",
    "alpha = 0.05  # 95% confidence\n",
    "\n",
    "# Compute sample mean and variance\n",
    "mean_X = np.sum(X * f_X) / np.sum(f_X)\n",
    "var_X = np.sum(f_X * (X - mean_X)**2) / np.sum(f_X)\n",
    "std_X = np.sqrt(var_X)\n",
    "n = np.sum(f_X)  # Sample size\n",
    "\n",
    "# CI for the mean\n",
    "t_critical = t.ppf(1 - alpha / 2, df=n - 1)\n",
    "mean_margin = t_critical * (std_X / np.sqrt(n))\n",
    "ci_mean = (mean_X - mean_margin, mean_X + mean_margin)\n",
    "\n",
    "# CI for the variance\n",
    "chi2_critical_low = chi2.ppf(alpha / 2, df=n - 1)\n",
    "chi2_critical_high = chi2.ppf(1 - alpha / 2, df=n - 1)\n",
    "ci_variance = (\n",
    "    (n - 1) * var_X / chi2_critical_high,\n",
    "    (n - 1) * var_X / chi2_critical_low,\n",
    ")\n",
    "\n",
    "# Results\n",
    "print(\"Sample Mean:\", mean_X)\n",
    "print(\"Sample Variance:\", var_X)\n",
    "print(\"95% CI for the Mean:\", ci_mean)\n",
    "print(\"95% CI for the Variance:\", ci_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why the $t$-distribution is used**\n",
    "- You’re correct: when we estimate the population standard deviation ($\\sigma$) using the sample standard deviation ($s$), we introduce some extra uncertainty.\n",
    "- The $t$-distribution is broader (has heavier tails) than the normal distribution, which accounts for this uncertainty.\n",
    "- As the sample size increases, our estimate of $\\sigma$ becomes more reliable, and the $t$-distribution approaches the normal distribution.\n",
    "\n",
    "**Confidence Intervals (CI) for the Mean**\n",
    "- A small CI: The data is tightly clustered, meaning less variability and more certainty in our estimate of the mean.\n",
    "- A large CI: Greater variability in the data leads to more uncertainty about the true mean. It reflects the randomness in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theory**\n",
    "\n",
    "**1. Confidence Interval for $\\mu_1 - \\mu_2$  (Equal Variances)**\n",
    "\n",
    "If variances are equal ($\\sigma_1 = \\sigma_2 = \\sigma$), the test statistic is:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p \\cdot \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $s_p^2$ is the pooled variance:\n",
    "\n",
    "$$\n",
    "s_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}\n",
    "$$\n",
    "\n",
    "\n",
    "The confidence interval is:\n",
    "\n",
    "$$\n",
    "\\left[ (\\bar{X}_1 - \\bar{X}2) - t{\\alpha/2, df} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}, \\, (\\bar{X}_1 - \\bar{X}2) + t{\\alpha/2, df} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} \\right]\n",
    "$$\n",
    "\n",
    "**2. Confidence Interval for $\\mu_1 - \\mu_2$ (Unequal Variances)**\n",
    "\n",
    "If variances are not equal ($\\sigma_1 \\neq \\sigma_2$), the test statistic is:\n",
    "\n",
    "$t = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$\n",
    "\n",
    "Degrees of freedom are approximated using Welch’s formula:\n",
    "\n",
    "$$\n",
    "df = \\frac{\\left(\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}\\right)^2}{\\frac{\\left(\\frac{s_1^2}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{s_2^2}{n_2}\\right)^2}{n_2 - 1}}\n",
    "$$\n",
    "\n",
    "**3. Confidence Interval for the Ratio of Variances**\n",
    "\n",
    "The ratio of variances  F =$\\frac{s_1^2}{s_2^2}$ follows an F-distribution with degrees of freedom $df_1 = n_1 - 1$, $df_2 = n_2 - 1$. The confidence interval is:\n",
    "\n",
    "$$\n",
    "\\left[ \\frac{s_1^2}{s_2^2} \\cdot \\frac{1}{F_{\\alpha/2, df_1, df_2}}, \\, \\frac{s_1^2}{s_2^2} \\cdot F_{1-\\alpha/2, df_1, df_2} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference CI (Equal variances): (5.173993799762329, 9.406006200237677)\n",
      "Mean difference CI (Unequal variances): (5.121993409516845, 9.45800659048316)\n",
      "Variance ratio CI: (0.06623875510686103, 1.073639404466911)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t, f\n",
    "\n",
    "# Data\n",
    "premium = np.array([22.4, 24.5, 21.6, 22.4, 24.8, 21.7, 23.4, 23.3, 21.6, 20.0])\n",
    "regular = np.array([17.7, 14.8, 19.6, 19.6, 12.1, 14.8, 15.4, 12.6, 14.0, 12.2])\n",
    "\n",
    "alpha = 0.05  # 95% confidence\n",
    "\n",
    "# Sample sizes, means, and variances\n",
    "n1, n2 = len(premium), len(regular)\n",
    "mean1, mean2 = np.mean(premium), np.mean(regular)\n",
    "var1, var2 = np.var(premium, ddof=1), np.var(regular, ddof=1)  # Sample variance\n",
    "\n",
    "# 1. Confidence interval for mean difference (Equal variances)\n",
    "sp2 = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)  # Pooled variance\n",
    "sp = np.sqrt(sp2)\n",
    "t_critical_equal = t.ppf(1 - alpha / 2, df=n1 + n2 - 2)  # t critical value\n",
    "margin_equal = t_critical_equal * sp * np.sqrt(1 / n1 + 1 / n2)\n",
    "ci_mean_equal = ((mean1 - mean2) - margin_equal, (mean1 - mean2) + margin_equal)\n",
    "\n",
    "# 2. Confidence interval for mean difference (Unequal variances)\n",
    "se_diff = np.sqrt(var1 / n1 + var2 / n2) # Standard error of the difference\n",
    "df_welch = (var1 / n1 + var2 / n2)**2 / ((var1 / n1)**2 / (n1 - 1) + (var2 / n2)**2 / (n2 - 1)) # Welch's degrees of freedom\n",
    "t_critical_unequal = t.ppf(1 - alpha / 2, df=df_welch) # ppf: Percent point function (inverse of cdf)\n",
    "margin_unequal = t_critical_unequal * se_diff\n",
    "ci_mean_unequal = ((mean1 - mean2) - margin_unequal, (mean1 - mean2) + margin_unequal)\n",
    "\n",
    "# 3. Confidence interval for ratio of variances\n",
    "f_critical_low = f.ppf(alpha / 2, dfn=n1 - 1, dfd=n2 - 1) # matlab: finv(alpha/2, n1-1, n2-1)\n",
    "f_critical_high = f.ppf(1 - alpha / 2, dfn=n1 - 1, dfd=n2 - 1)\n",
    "ci_variance_ratio = (var1 / var2 / f_critical_high, var1 / var2 / f_critical_low)\n",
    "\n",
    "# Results\n",
    "print(\"Mean difference CI (Equal variances):\", ci_mean_equal)\n",
    "print(\"Mean difference CI (Unequal variances):\", ci_mean_unequal)\n",
    "print(\"Variance ratio CI:\", ci_variance_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
