[
  {
    "question": "In order to overcome the perceptron's limits, we can:",
    "answers": [
      "use neurons with a continuous threshold",
      "use kernel transformations on the domain",
      "these limits can't be overcome",
      "increase the number of neurons"
    ],
    "correct": "ad"
  },
  {
    "question": "What problems can be solved with machine learning?",
    "answers": [
      "regressions",
      "???",
      "plannings and classifications",
      "none of the above"
    ],
    "correct": "ac"
  },
  {
    "question": "The objective of a machine learning algorithm can be represented as:",
    "answers": [
      "numeric functions",
      "probabilistic functions",
      "a set of symbolic rules",
      "a table"
    ],
    "correct": "abcd"
  },
  {
    "question": "The induction phase for the process of building a decision tree is:",
    "answers": [
      "it labels the new data with the build rules",
      "it eliminates the branches that reflect noise & exceptions",
      "based on the training data",
      "works bottom-up or top-down"
    ],
    "correct": "cd"
  },
  {
    "question": "What is a tensor?",
    "answers": [
      "an image with multiple",
      "a mathematical object",
      "generalizations of scalars, vectors, and matrices in an arbitrary number of indices",
      "none of the above"
    ],
    "correct": "bc"
  },
  {
    "question": "Select the correct combination(s):",
    "answers": [
      "Output type: Continuous Output distribution: Gaussian Output layer: Linear Cost function: MSE",
      "Output type: Discrete Output distribution: Multinoulli Output layer: Softmax Cost function: Cross Entropy",
      "Output type: Binary Output distribution: Bernoulli Output layer: Sigmoid Cost function: BCE",
      "none of the above"
    ],
    "correct": "abc"
  },
  {
    "question": "What are the differences and similarities between the perceptron's rule and the delta rule?",
    "answers": [
      "In the delta rule, the model's quality is established based on all the data.",
      "The perceptron's rule is based on gradient descent.",
      "They both start with some random weights.",
      "Perceptron's rule recomputes the weights based on while the delta rule.",
      "The perceptron rule and delta rule always converge to the global optimum and are not affected by local minima.",
      "The perceptron rule and delta rule do not require any iterative optimization process and can achieve optimal weights in a single pass."
    ],
    "correct": "ac"
  },
  {
    "question": "What elements determine the velocity of a particle in a PSO algorithm (check all correct ones):",
    "answers": [
      "the old velocity",
      "inertia, social coefficient",
      "the current position of the particle",
      "none of the above"
    ],
    "correct": "abc"
  },
  {
    "question": "The limited model capacity of an ANN can be overcome by:",
    "answers": [
      "adding more layers in depth",
      "reducing the number of artificial neurons",
      "adding nonlinearity to the model",
      "none of the above"
    ],
    "correct": "ac"
  },
  {
    "question": "What is the fitness function for the following problem: \"There is a set of M cards printed with integer numbers from -10 to 10. Select two subsets (that have no common elements and do not necessarily form a partition) using a GA, in such a way that they have the same sum of elements\"?",
    "answers": [
      "the absolute value of the sum of the selected elements from the first set / the number of elements from the second set.",
      "the difference in absolute value between the sum of the subset' elements and their divisors",
      "the difference in absolute value between the sums of elements from each subset",
      "the number of elements"
    ],
    "correct": "c"
  },
  {
    "question": "The Perceptron's algorithm:",
    "answers": [
      "is based on error minimization associated with an instance of train data",
      "the error is the difference between the real output y and the output o computed by the perceptron for an input",
      "it modifies the weights based on errors associated with an instance of train data",
      "none of the above"
    ],
    "correct": "abc"
  },
  {
    "question": "The \"dying ReLU\" problem refers to:",
    "answers": [
      "the values of the derivative",
      "the vanishing gradient",
      "the values of the function",
      "none of the above"
    ],
    "correct": "a"
  },
  {
    "question": "Choose the correct compatibility between the error function and the activation function from the output layer:",
    "answers": [
      "cross entropy error with softmax",
      "binary cross entropy with logistic error with the sigmoid activation function",
      "mean square error with the linear function",
      "none of the above"
    ],
    "correct": "ac"
  },
  {
    "question": "How does a ConvNet compute an image?",
    "answers": [
      "in such a network, the filters results are never combined",
      "there is automation in detecting the weights for the kernels",
      "there are usually three stages; several convolutions, a detector stage, and a pooling stage",
      "none of the above"
    ],
    "correct": "bc"
  },
  {
    "question": "Select the correct statements for Cross-Entropy loss:",
    "answers": [
      "is used in classifications",
      "is the difference between two probability distributions for a provided set of occurrences or random variables",
      "is never used after the softmax transformation after output",
      "none of the above"
    ],
    "correct": "ab"
  },
  {
    "question": "What are the properties of the training and testing data?",
    "answers": [
      "they have to respect the same distribution law",
      "the test data should be based on real experiences, and the training should be based on theoretical experiences",
      "if possible, the training and the data test should be disjunct sets",
      "none of the above"
    ],
    "correct": "ac"
  },
  {
    "question": "The harmonic mean between the precision and the recall is:",
    "answers": [
      "a metric for distance in a reinforcement learning algo",
      "the F1 score",
      "a statistical metric used to evaluate performance in a supervised learning process",
      "none of the above"
    ],
    "correct": "bc"
  },
  {
    "question": "When we compare two algorithms, we can use:",
    "answers": [
      "the divergence of the Accuracy",
      "confidence intervals",
      "performance measures",
      "none of the above"
    ],
    "correct": "bc"
  },
  {
    "question": "How are the neurons connected in a feed forward ANN?",
    "answers": [
      "through a backward signal",
      "through an output with a neuron from the same layer",
      "they are not connected",
      "through weighted links"
    ],
    "correct": "d"
  },
  {
    "question": "What sort of problems can a perceptron solve?",
    "answers": [
      "linear separation of elements from the domain",
      "XOR problem",
      "depends on the structure",
      "none of the above"
    ],
    "correct": "bc"
  },
  {
    "question": "The vanishing gradients during backpropagation are:",
    "answers": [
      "not affecting us since the derivative is zero in this case on most of the domain",
      "are advantage in the training process that leads to faster convergence",
      "a typical problem when the network has too many hidden layers",
      "none of the above"
    ],
    "correct": "c"
  },
  {
    "question": "The activation logistic function:",
    "answers": [
      "is a linear function",
      "suffers from a vanishing gradient",
      "has limitations regarding the output domain",
      "has limitations regarding the input domain",
      "none of the above"
    ],
    "correct": "bc"
  },
  {
    "question": "An ANN with a structure of 226:15:10:2 with a sigmoid activation function. How many weights will the first neuron from the first hidden layer have?",
    "answers": [
      "2",
      "226",
      "10",
      "15"
    ],
    "correct": "b"
  },
  {
    "question": "In an artificial neuron, the transfer function:",
    "answers": [
      "is the equation of a hyperplane",
      "its nature limits the solving capacity of the neuron",
      "is the inner product of the input vector with the weight vector",
      "it can be the sigmoid function"
    ],
    "correct": "d"
  },
  {
    "question": "The indirect experience when choosing the training database is:",
    "answers": [
      "in pairs (in/out)",
      "useful feedback for the objective function",
      "based on independent data with annotated content",
      "none of the above"
    ],
    "correct": "b"
  },
  {
    "question": "On a ConvNet, feature learning:",
    "answers": [
      "will minimize the loss function by extracting those who are most useful for classifying the images.",
      "allows a suite of tens or even hundreds of other small filters to be designed in order to detect more complex features in the image",
      "is performed before training the conv. layers",
      "none of the above"
    ],
    "correct": "ab"
  },
  {
    "question": "We can implement the infinite summation as a sum over a finite number of array elements:",
    "answers": [
      "in practice, we have two tensors: the input and the kernel",
      "such implementation is impossible in practice",
      "the input and the kernel are zero everywhere bet in the finite set of points",
      "by using a convolution operation"
    ],
    "correct": "d"
  },
  {
    "question": "Clustering is:",
    "answers": [
      "a process in two steps: training and testing",
      "using an unlabeled database",
      "another name for unsupervised learning",
      "none of the above"
    ],
    "correct": "abc"
  },
  {
    "question": "What are the correct statements about Decision Trees?",
    "answers": [
      "The decision nodes are located at the terminal levels of the tree while the result nodes are at the internal levels.",
      "Each leaf of the tree corresponds to a specific attribute or feature.",
      "They are used to divide a collection of articles into smaller sets by successively applying decision rules.",
      "Decision trees contain four types of nodes: decision nodes, hazard nodes, class nodes, and result nodes."
    ],
    "correct": "c"
  },
  {
    "question": "The activation logistic function:",
    "answers": [
      "suffers from vanishing gradient.",
      "is a linear function.",
      "has limitations regarding the input domain.",
      "none of the above."
    ],
    "correct": "a"
  },
  {
    "question": "Clustering is:",
    "answers": [
      "a one-step process: testing.",
      "Another name for unsupervised learning.",
      "using a labeled database.",
      "none of the above."
    ],
    "correct": "b"
  },
  {
    "question": "What is a feature of the database in training with indirect experience:",
    "answers": [
      "it is based on useful feedback for some objective function.",
      "it comes in pairs (in/out).",
      "it is based on independent data with annotated content.",
      "none of the above."
    ],
    "correct": "a"
  },
  {
    "question": "An ANN has a structure of 26:15:10:2 with a sigmoid activation function. How many weights will have the first neuron from the first hidden layer?",
    "answers": [
      "2",
      "15",
      "26",
      "10"
    ],
    "correct": "c"
  },
  {
    "question": "When constructing a decision tree, the attribute selection can be:",
    "answers": [
      "In preorder.",
      "Random.",
      "Based on the top parent.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "The induction phase of the process of building a Decision Tree is:",
    "answers": [
      "It labels the new data with the built rules.",
      "It eliminates the branches that reflect noise or exception",
      "Based on the training data.",
      "Works bottom to bottom or top to top."
    ],
    "correct": "c"
  },
  {
    "question": "The back-propagation algorithm:",
    "answers": [
      "Is a training algorithm for ANNs.",
      "Guarantees finding the optimal set of weights and biases in a finite number of iterations.",
      "Can only be applied to shallow neural networks and is not suitable for deep learning architectures.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "Select the correct statements for Cross-Entropy loss:",
    "answers": [
      "Is never used when we apply the softmax transformation to the network's output.",
      "Is used in regressions.",
      "Is the difference between two probability distributions for a provided set of occurrences or random variables.",
      "None of the above."
    ],
    "correct": "c"
  },
  {
    "question": "What are the characteristics of the back-propagation algorithm?",
    "answers": [
      "It is crossing easy plateaus in the error function landscape.",
      "Does not require the derivatives of activation functions to be known at network design time.",
      "Is guaranteed to find the global minimum of the error function, not only the local minimum.",
      "None of the above."
    ],
    "correct": "d"
  },
  {
    "question": "What is the proper encoding for an individual in ANNs?",
    "answers": [
      "A computer program that learns to classify and performs regressions.",
      "A set of weights used to propagate a signal.",
      "There are no individuals in ANN.",
      "An array of bits that encode proper information related to the solution."
    ],
    "correct": "c"
  },
  {
    "question": "On a ConvNet, the feature learning:",
    "answers": [
      "Allows a suite of tens or even hundreds of other small filters to be erased in order to detect more complex features in the image.",
      "Is performed before training the conv-layers.",
      "Will minimize the loss function by extracting the features that are most useful for classifying the images.",
      "None of the above."
    ],
    "correct": "c"
  },
  {
    "question": "The \"dying ReLU\" problem refers to:",
    "answers": [
      "The values of the derivative.",
      "The values of the function.",
      "The vanishing gradient.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "The universal approximation theorem states that:",
    "answers": [
      "Any function can be approximated with a proper neural network.",
      "There should be enough neurons on the hidden layer in order to do the approximation.",
      "The conditions to approximate a function include the continuity of that function.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "What is a tensor?",
    "answers": [
      "A generalization of scalars, vectors, and matrices to an arbitrary number of indices.",
      "A mathematical object that contains a one-dimensional array of values.",
      "A black and white image with multi-channels.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "How does a ConvNet figure out what is in an image?",
    "answers": [
      "Automatically detecting the weights for the kernels during training.",
      "By decomposing the features.",
      "There are usually three stages: several convolutions, a decomposing stage, a flatten stage.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "The softmax function:",
    "answers": [
      "Transforms in probabilities the output scores for the classes.",
      "It incorporates the cross-entropy function.",
      "Is used in regressions.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "Select the correct combination:",
    "answers": [
      "Output type: Discrete, Output Distribution: Multinoulli, Output Layer: Linear, Cost Function: Cross Entropy.",
      "Output type: Binary, Output Distribution: Bernoulli, Output Layer: Sigmoid, Cost Function: Binary Cross Entropy.",
      "Output type: Continuous, Output Distribution: Gaussian, Output Layer: Softmax, Cost Function: MSE.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "The L1 loss is:",
    "answers": [
      "It computes the average of the sum of absolute differences between actual values and predicted ones",
      "Used for classification problems",
      "Is also called the softmax loss",
      "Is never used when the distribution has outliers"
    ],
    "correct": "a"
  },
  {
    "question": "What is the difference between Particle Swarm Optimization (PSO) and Genetic Algorithms (GA)?",
    "answers": [
      "PSO runs free until it converges to the solution, while GA never reaches the solution",
      "The particles have a memory, while the individuals don't",
      "GA has particles, and PSO has individuals",
      "GA uses a fitness function, and PSO doesn't"
    ],
    "correct": "b"
  },
  {
    "question": "How does the artificial neuron process the information?",
    "answers": [
      "Based on backpropagation",
      "Based on the activation function",
      "Based on the error",
      "None of the above"
    ],
    "correct": "b"
  },
  {
    "question": "What are the main advantages of Deep Convolutional Neural Networks?",
    "answers": [
      "The architecture of a ConvNet is analogous to that of the connectivity pattern of neurons in an Artificial Cortex",
      "A ConvNet captures the feature gradient dependencies in a time series",
      "The preprocessing required in a ConvNet is much lower as compared to other classification algorithms",
      "None of the above"
    ],
    "correct": "c"
  },
  {
    "question": "What can be used when comparing two algorithms?",
    "answers": [
      "The divergence of accuracy",
      "Overconfidence intervals",
      "Performance measures",
      "None of the above"
    ],
    "correct": "c"
  },
  {
    "question": "What are the advantages of going in depth in an ANN?",
    "answers": [
      "To avoid overfitting",
      "To speed up the network's evaluation",
      "We avoid underfitting the model",
      "None of the above"
    ],
    "correct": "ac"
  },
  {
    "question": "How is the objective of a machine learning algorithm typically represented?",
    "answers": [
      "A database table",
      "Numeric functions",
      "Distributions of probability",
      "A set of non-symbolic rules"
    ],
    "correct": "b"
  },
  {
    "question": "In order to overcome the perceptron's limits, we can:",
    "answers": [
      "Installing additional RAM directly enhances the neuron's processing power",
      "These limits can't be overcome",
      "Use neurons with a continuous threshold",
      "Applying the glitter property to the perceptron's activation function improves its ability to learn"
    ],
    "correct": "c"
  },
  {
    "question": "The vanishing gradients during backpropagation is:",
    "answers": [
      "An advantage in the training process that leads to faster convergence",
      "Since the derivative is zero in this case, on most of the domain, it does not affect us",
      "A problem typical when the network has too many hidden layers",
      "None of the above"
    ],
    "correct": "c"
  },
  {
    "question": "What problems can be solved with machine learning?",
    "answers": [
      "Ethical and moral considerations",
      "Planning and classifications",
      "Creative problems that require innovation",
      "None of the above"
    ],
    "correct": "b"
  },
  {
    "question": "The harmonic mean between precision and recall is:",
    "answers": [
      "A measure for distance in certain clustering algorithms.",
      "The F1 score, which combines precision and recall into a single value.",
      "A metric used to evaluate the trade-off between precision and recall in deterministic algorithms.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "The information gain ratio:",
    "answers": [
      "It aims to reduce a bias towards multivalued attributes.",
      "Is the ratio between the information gain and the split information.",
      "It enhances an attribute by integrating a new term that depends on spreading degree.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "We can implement the infinite summation as a sum over a finite number of array elements:",
    "answers": [
      "Such implementation is impossible in practice.",
      "In practice, we have two tensors: the input and the padding.",
      "By using a convolution operation.",
      "The input, the padding, and the kernel contain random numbers everywhere in the beginning."
    ],
    "correct": "c"
  },
  {
    "question": "What are the differences and similarities between the perceptron's rule and the delta rule?",
    "answers": [
      "The perceptron rule and delta rule always converge to the global optimum and are not affected by local minima.",
      "The perceptron rule and delta rule do not require any iterative optimization process and can achieve optimal weights in a single pass.",
      "They both start with some random weights.",
      "None of the above."
    ],
    "correct": "c"
  },
  {
    "question": "For Unsupervised Learning, choose the appropriate statement:",
    "answers": [
      "The training data comes in pairs: (attributes, outputs).",
      "It finds an unknown function that groups the training data into several classes.",
      "The goal is to find a model or structure inside the data that is useful.",
      "None of those things."
    ],
    "correct": "bc"
  },
  {
    "question": "The ReLU function:",
    "answers": [
      "Provides sparsity since y = 0 when x > 0",
      "Does not correct the problems that occur at sigmoid function",
      "It is a linear activation function",
      "Does not have a vanishing gradient when x > 0"
    ],
    "correct": "d"
  },
  {
    "question": "What elements determine the new velocity of a particle in a PSO algorithm? (check all correct ones)",
    "answers": [
      "The current position of the weakest particle",
      "Inertia, social coefficient",
      "The old velocity of the best particle",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "In computer vision, we apply a filter over an image:",
    "answers": [
      "By using a convolution operation with a kernel",
      "Moving the kernel and adding to the part of the image that the kernel is hovering over.",
      "In order to preprocess the input by subtracting some features from the initial image.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "Choose the correct answer.",
    "answers": [
      "Backpropagation is insensitive to the choice of activation functions and can perform equally well with any activation function.",
      "The gradient descent is based on the error associated with the entire set of train data.",
      "Adding more training data will always result in better generalization and performance for the ANN.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "What is standardization?",
    "answers": [
      "A data transformation that introduces the scale effect.",
      "The process by which raw values are transformed into z-scores.",
      "The operation that transforms continuous values into discrete ones.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "What crossover method(s) are correct for a binary representation in a GA?",
    "answers": [
      "Uniform",
      "There is no crossover for this representation",
      "Average crossover",
      "Insertion mutation"
    ],
    "correct": "a"
  },
  {
    "question": "Using a feed forward ANN we want to determine if a shape from a black-and-white image is a square or not. How is the error computed?",
    "answers": [
      "Based on the output of the hidden layer.",
      "Based on an induction formula.",
      "Based on the difference between the real output of the network and the desired output.",
      "None of the above."
    ],
    "correct": "c"
  },
  {
    "question": "Which factor is the primary consideration when selecting an appropriate learning algorithm?",
    "answers": [
      "Ability to predict cluster membership.",
      "Minimization of error through a cost function or loss function.",
      "Alignment with the desired data.",
      "Computational complexity of the target objective."
    ],
    "correct": "c"
  },
  {
    "question": "Choose the right compatibility between the output layer's activation function and error function:",
    "answers": [
      "Mean square error with the linear function.",
      "Binary cross entropy with logistic error with the sigmoid activation function.",
      "Cross entropy error with arctangent.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "In an artificial neuron, the transfer function:",
    "answers": [
      "Represents the equation of a hyperplane.",
      "Utilizes entanglement to calculate the output.",
      "Requires the neuron to perform complex mathematical operations with imaginary numbers.",
      "Is the sigmoid function."
    ],
    "correct": "a"
  },
  {
    "question": "The Perceptron's algorithm:",
    "answers": [
      "It changes the weights based on the inverse error associated with a train data instance.",
      "Is based on maximizing the error for a given set of train data.",
      "The error is the difference between what the real output y is and what the perceptron's output o is for a given input.",
      "None of the above."
    ],
    "correct": "c"
  },
  {
    "question": "What is the relationship between the training and testing data?",
    "answers": [
      "The test data should reflect real-life experiences, while the training data can be based on theoretical experiences.",
      "They should follow the same distribution.",
      "The two sets must overlap.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "What sort of problems can a perceptron solve?",
    "answers": [
      "Linear separations of elements from the domain.",
      "It depends on the structure.",
      "XOR problem.",
      "None of the above."
    ],
    "correct": "a"
  },
  {
    "question": "The limited model capacity of ANNs is overcome by:",
    "answers": [
      "Reducing the number of artificial neurons.",
      "Adding nonlinearity to the model.",
      "Adding more layers at the output level.",
      "None of the above."
    ],
    "correct": "b"
  },
  {
    "question": "Select the correct statement for supervised learning:",
    "answers": [
      "The aim is to provide an arbitrary output for a new input.",
      "The training data comes in an unpaired format: only attributes or only output.",
      "We search for a known function that maps the input attributes to the outputs.",
      "None of the above."
    ],
    "correct": "d"
  },
  {
    "question": "How are the neurons connected into a feed forward ANN?",
    "answers": [
      "Through a backward signal.",
      "Through an output with a neuron from the same layer.",
      "They are not connected.",
      "Through weighted links."
    ],
    "correct": "d"
  },
  {
    "question": "Which of the following statements is true when we apply a max pooling transformation over a tensor:",
    "answers": [
      "We return the maximum value from the portion of the image covered by the kernel.",
      "We handle inputs of different types.",
      "We emphasize the features.",
      "We make the representation dependent on small translations of the input."
    ],
    "correct": "ad"
  }
]